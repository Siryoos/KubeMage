models:
    chat: llama3.1:8b
    generation: llama3.1:13b
num_ctx: 4096
keep_alive: 5m
truncation:
    message: 1200
theme: default
history_length: 10
ollama_host: http://localhost:11434
